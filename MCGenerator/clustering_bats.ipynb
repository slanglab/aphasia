{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6860fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os, re\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c7a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path):\n",
    "    data=[]\n",
    "    with open(path, 'r', encoding='utf-8') as reader:\n",
    "        for line in reader:\n",
    "            data.append(json.loads(line))\n",
    "    return data \n",
    "\n",
    "def save_jsonl(name, data):\n",
    "    with open(name, 'w') as outfile:\n",
    "        for entry in data:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6d9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_concepts(stimuli_name: str) -> dict:\n",
    "    with open('../data/BATS/goldMCs/' + stimuli_name + '.json', 'r') as f:\n",
    "        concepts = json.load(f)\n",
    "    return concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3df483ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_concepts_dir = '../MCGenerator/Responses/zero_shot/llama3/original_narrative_input/monte-carlo-same-temp/'\n",
    "eval_response_save_dir = './Responses/zero_shot/gpt4o/original_narrative_input/monte-carlo-same-temp-decomposed-mcs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83faf07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_stimuli = ['MarcusYam', 'SylviaEarle', 'NaomiDeLaRosa', 'RobinSteinberg']\n",
    "sd_stimuli = ['AuntMother', 'Ferguson', 'Sept11', 'NoHandbook']\n",
    "list_of_stimuli = sd_stimuli+vs_stimuli\n",
    "\n",
    "stimuli2nummc = {'AuntMother':7,\\\n",
    "                 'Ferguson':10,\\\n",
    "                 'Sept11':12,\\\n",
    "                 'NoHandbook':11,\\\n",
    "                 'MarcusYam':11,\\\n",
    "                 'SylviaEarle':8,\\\n",
    "                 'NaomiDeLaRosa':8,\\\n",
    "                 'RobinSteinberg':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "795383cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli2mcs = {}\n",
    "for prompt_name in os.listdir(generated_concepts_dir):\n",
    "    if '.ipynb_checkpoints' in prompt_name: continue\n",
    "    data = load_jsonl(generated_concepts_dir+'/'+prompt_name.split('/')[-1])\n",
    "    for r in data:\n",
    "        if r['Stimuli'] not in stimuli2mcs:\n",
    "            stimuli2mcs[r['Stimuli']] = r['decomposed_mcs']\n",
    "        else:\n",
    "            stimuli2mcs[r['Stimuli']].extend(r['decomposed_mcs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f159f6b",
   "metadata": {},
   "source": [
    "### Cluster MCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf7ccc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankitagupta/anaconda3/envs/supcourt/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/ankitagupta/anaconda3/envs/supcourt/lib/python3.9/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ankitagupta/anaconda3/envs/supcourt/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c92775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from pdc_dp_means import DPMeans\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"Compute the cosine similarity between two vectors.\"\"\"\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    return np.dot(v1, v2) / (norm_v1 * norm_v2)\n",
    "\n",
    "def find_closest_examples(n_clusters, cluster_centers, embeddings, cluster_predictions, mcs):\n",
    "    closest_examples = {}\n",
    "\n",
    "    for cluster in range(n_clusters):\n",
    "        if cluster not in cluster_predictions: continue\n",
    "        cluster_indices = np.where(cluster_predictions == cluster)[0]\n",
    "        cluster_embeddings = embeddings[cluster_indices]\n",
    "        \n",
    "        similarities = [\n",
    "            cosine_similarity(embedding, cluster_centers[cluster]) \n",
    "            for embedding in cluster_embeddings\n",
    "        ]\n",
    "        closest_index_in_cluster = np.argmax(similarities)\n",
    "\n",
    "        closest_examples[cluster] = mcs[cluster_indices[closest_index_in_cluster]]\n",
    "\n",
    "    return closest_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db13d642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/8 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 8/8 [02:05<00:00, 15.67s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "from pdc_dp_means import DPMeans\n",
    "deltas = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 5, 10, 15, 20]\n",
    "\n",
    "mcs_per_stimuli = {}\n",
    "for stimuli in tqdm(list_of_stimuli):\n",
    "    mcs = stimuli2mcs[stimuli]\n",
    "    mcs = [m for m in mcs if m!='']\n",
    "    mc_embeddings = model.encode(mcs)\n",
    "    mc_embeddings = mc_embeddings.astype(np.float64)\n",
    "    mc_embeddings = normalize(mc_embeddings, norm='l2')\n",
    "    assert mc_embeddings.shape[0]==len(mcs), 'error in embedding process'\n",
    "    \n",
    "    mcs_per_delta = {}\n",
    "    for delta in deltas:\n",
    "        from pdc_dp_means import DPMeans\n",
    "        dpmeans = DPMeans(n_init=1, delta=delta)  # n_init and delta parameters\n",
    "        dpmeans.fit(mc_embeddings)\n",
    "\n",
    "        cluster_predictions = dpmeans.predict(mc_embeddings)\n",
    "        cluster_centers = dpmeans.cluster_centers_\n",
    "        n_clusters = dpmeans.n_clusters\n",
    "        closest_examples = find_closest_examples(n_clusters, cluster_centers,\\\n",
    "                                                 mc_embeddings,\\\n",
    "                                                 cluster_predictions,\\\n",
    "                                                 mcs)\n",
    "\n",
    "        mcs_per_delta[delta] = {'closest_examples': list(closest_examples.values()),\n",
    "                                  'n_clusters': n_clusters,\\\n",
    "                                  'cluster_predictions': cluster_predictions,\\\n",
    "                                  'cluster_centers': cluster_centers}\n",
    "    \n",
    "    mcs_per_stimuli[stimuli] = mcs_per_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "# with open('./clustering_results/bats/deduplicated_mcs_clustering_run2.pickle', 'wb') as f:\n",
    "#     pickle.dump(mcs_per_stimuli, f)\n",
    "    \n",
    "import pickle \n",
    "with open('./clustering_results/bats/deduplicated_mcs_clustering_run2.pickle', 'rb') as f:\n",
    "    mcs_per_stimuli = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
